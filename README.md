# SSHS-DataStructure

GL HF

## 목차

1. [자료구조와 알고리즘](#1-자료구조와-알고리즘)
2. [순차 자료구조](#2-순차-자료구조)
    * [배열](#배열)
    * [다항식](#다항식)
    * [행렬](#행렬)
3. [연결 자료구조](#3-연결-자료구조)
    * [단순 연결 리스트](#단순-연결-리스트)
    * [원형 연결 리스트](#원형-연결-리스트)
    * [이중 연결 리스트](#이중-연결-리스트)
4. [스택](#4-스택)
    * [구현 - 순차 자료구조](#순차-자료구조스택)
    * [구현 - 연결 자료구조](#연결-자료구조스택)
    * [응용 - 후위 표기식](#응용---후위-표기법-변환)
5. [큐](#5-큐)
    * [구현 - 순차 자료구조](#순차-자료구조큐)
    * [구현 - 연결 자료구조](#연결-자료구조큐)
    * [덱](#덱)
6. [트리](#6-트리)
    * [이진 탐색 트리](#이진-탐색-트리)
    * [AVL 트리](#avl-트리)
    * [Heap](#heap)
7. [정렬](#7-정렬)
    * [선택, 버블, 삽입 정렬](#selection--bubble--insertion-sort)
    * [쉘 정렬](#shell-sort)
    * [퀵 정렬](#quick-sort)
    * [병합 정렬](#merge-sort)
    * [힙 정렬](#heap-sort)
    * [기수 정렬](#radix-sort)
    * [팀 정렬](#tim-sort)
8. [그래프](#8-그래프)
    * [프림 알고리즘](#prims-algorithm)
9. [해싱](#9-탐색)

## 1. 자료구조와 알고리즘

***최근 N년간 기출에 나온 적 없기 때문에 시험에 나오지 않을 것으로 추정됨.***

### 알고리즘

* 알고리즘: 특정한 일을 수행하는 명멸어들의 **유한** 집합
* 알고리즘의 조건
    1. 입력: 외부에서 제공되는 데이터가 0개 이상
    2. 출력: 적어도 1개 이상의 결과 생성
    3. 명확성: 각 명령들은 명확해야 함
    4. 유한성: 알고리즘의 명령대로 수행하면 한정된 수의 단계 뒤에는 반드시 종료함
    5. 유효성: 모든 명령들이 실행 가능한 것이어야 함

전산학에서 프로그램은 유한성 조건을 만족하지 않아도 된다.

### 데이터 타입

* 데이터 타입: 객체와 그 객체 위에서 작동하는 연산의 집합
* 추상화: 사용자에게 중요한 정보만 강조되며, 중요치 않은 세부 구현 사항은 제거하는 것
* 추상 데이터 타입: 객체의 명세와 그 연산의 명세가 그 객체의 표현 및 연산의 구현으로부터 분리된 데이터 타입
* 추상 데이터 타입 함수의 범주
    1. 생성자 / 구성자
    2. 변환자
    3. 관찰자 / 보고자

### 재귀

* 재귀 함수: 자기 자신을 다시 호출하는 함수
* 분할 정복 알고리즘을 구현할 때 주로 사용됨

## 2. 순차 자료구조

* 선형 리스트의 원소들 간의 논리적인 순서와 물리적인 순서가 같도록 하는 구조
* 배열 / 리스트 등

### 배열

#### 객체

`<index, item>`의 쌍, `Array[index]`를 통해 접근

#### 연산

* 삽입: 뒤의 원소들의 index를 1씩 증가시킨 후 삽입
* 삭제: 삭제한 후 뒤의 원소들의 index를 1씩 감소시킴

#### 장점

* 배열 내의 특정 데이터에 빠르게 접근할 수 있음
* 정적인 데이터 처리에서 기억장소를 효율적으로 활용

#### 단점

* 배열 내의 특정 위치에 데이터 삽입/삭제가 비효율적
* 배열의 크기는 정적이므로 최대로 선언해야 함

### 다항식

#### 다항식의 표현

1. $f(x) = a_nx^n + a_{n-1}x^{n-1} + \cdots + a_0$일 때, 배열 $A = [a_n, a_{n-1}, \cdots, a_0]$으로 저장
2. $a_i$에 $0$이 많을 경우 지수와 계수를 같이 저장

### 행렬

#### 행렬의 표현

1. $M_{ij} = A[i][j]$이도록 하는 2차원 배열 $A$
2. 희소 행렬의 경우 $M_{ij} \ne 0$일 때, $(i, j, M_{ij})$를 저장하는 정렬된 배열(0-based)

#### [희소 행렬의 전치](src/matrix.c)

$(i, j, value) \longmapsto (j, i, value)$로 변환시키며 정렬 순서를 유지해야 한다.

구현을 위해 아래와 같은 두 가지 배열을 구성한다.

* `rowTerms`: $j=idx$인 $j$의 개수를 $R[idx]$에 저장
* `startingPos`: $M^T$의 행 index별 시작 위치를 저장하는 배열, $S[0]=1$, $S[idx]=S[idx-1]+R[idx-1]$.

## 3. 연결 자료구조

원소의 삽입 및 삭제가 빈번하게 일어날 경우, 순차 자료구조는 한 번의 연산당 $O(N)$ 시간이 걸리므로 효율적이지 않다.

이를 해결하기 위해 연결 자료구조를 사용하며, 그 특징은 다음과 같다.
* 다음 노드의 위치를 앞 노드가 가리키고 있는 자료구조로, 삽입과 삭제가 용이하다. 
* 자료의 논리적인 순서와 물리적인 순서가 일치하지 않는다.
* 동적으로 구성된다.
* 탐색이 순차 자료구조(배열)보다 느리다.

### [단순 연결 리스트](src/simply_linked_list.c)

* 각 노드가 하나의 포인터 필드를 가지고 있는 리스트
* 리스트의 시작은 `head`
* 리스트의 끝은 `NULL`
* 0개 이상의 노드를 포함

#### 연산

* 삽입
* 삭제
* 탐색
* 연결: `lst1`의 맨 뒤에 `lst2`를 붙이는 연산
* 역순 재배열: `lst`의 데이터 순서를 역순으로 바꾼다.

#### 구현 방법

* 헤드 포인터
    * 낭비되는 공간이 없음
    * 맨 앞 노드의 처리를 case work
* 헤드 노드
    * 헤드 노드의 공간이 낭비됨
    * 헤드 노드를 제외한 노드들은 모두 선행 노드를 가지므로 구현이 간단함

### [원형 연결 리스트](src/circular_linked_list.c)

* 마지막 노드가 첫 번째 노드를 가리키는 리스트
* 한 노드에서 모든 노드로의 접근이 가능
* 원형 연결 리스트의 head는 보통 tail을 가리키게 함
    * 가장 앞쪽 및 뒤쪽에 원소를 삽입할 때 빠름

### [이중 연결 리스트](src/doubly_linked_list.c)

* 선행 노드와 후속 노드 두 개의 포인터를 저장하는 연결 리스트
* 단순 연결 리스트의 경우 선행 노드가 있어야 삭제 가능
* 이중 연결 리스트는 그 노드 자체를 삭제 가능
* 양방향으로 탐색 가능, 공간을 많이 차지하고 코드가 복잡함

이중 연결 리스트는 실제로 사용될 때 헤드 노드를 사용한 형태로 구현해야 간단하게 구현할 수 있다. 또 원형 연결 리스트와 같이 사용한 형태도 존재한다. 이 글에서는 원형 연결 리스트와 함께 결합한 형태로 구현했다.

## 4. 스택

스택은 후입 선출 / LIFO 구조를 가지는 순서 리스트의 특별한 경우다.

스택의 용어들은 아래와 같다.

* `top`: 상단의 원소
* `push`: 스택에 원소를 추가
* `pop`: 스택 상단의 원소를 제거하면서 반환

### 순차 자료구조(스택)

스택을 1차원 배열을 통해 구현하는 방법이다.

`top`은 마지막 원소의 인덱스를 저장하는 정수로 아래와 같이 공백 상태와 포화 상태를 구분한다.

* 공백 상태: `top = -1`
* 포화 상태: `top = n - 1`

#### 장점

* 구현이 쉬움

#### 단점

* 정적인 배열을 사용하기 때문에 스택의 크기 변경을 할 수 없다.
* 순차 자료구조의 단점을 그대로 가진다.

### [연결 자료구조(스택)](src/stack.c)

스택을 연결 리스트를 이용하여 구현하는 방법이다.

`top`은 연결 리스트의 head를 가리키는 포인터 변수로, 공백 상태를 확인할 수 있으며 포화 상태는 존재하지 않는다.

* 공백 상태: `top = NULL`

### 응용 - 올바른 괄호 문자열 판별

왼쪽에서 오른쪽으로 괄호를 하나씩 읽으며 판별하면 된다.

마지막에 스택이 공백 상태인지 확인해주어야 한다.

### [응용 - 후위 표기법 변환](src/postfix_calc.c)

이항 연산자는 아래와 같은 표기법을 쓸 수 있다.

* 전위 표기법: `*+ABC`
* 중위 표기법: `(A+B)*C`
* 후위 표기법: `AB+C*`

후위 표기법은 괄호를 사용하지 않고 직관적으로 계산을 할 수 있어 컴파일러는 후위 표기식을 사용한다.

따라서 컴파일러는 중위 표기식을 후위 표기식으로 바꾼 후, 후위 표기식을 계산하게 된다. 이 두 과정에서 모두 스택을 사용한다.

#### 중위 표기식 $\rightarrow$ 후위 표기식

연산자를 저장하는 스택 $S$를 만든 후, 주어진 중위 표기식의 왼쪽부터 끝(`\0` 포함)까지 차례대로 읽으면서 아래와 같은 과정을 수행한다.

* 숫자라면 그대로 출력하고 넘어간다.
* `)`라면 `(`가 나올 때까지 $S$의 원소들을 차례대로 `pop`하며 출력한다. 단, `(`는 출력하지 않는다.
* 다른 연산자면 $isp[S.top] \ge icp[curr]$인 동안 $S$에서 원소들을 pop하며 출력한다. 이후 $S$에 `curr`을 `push`한다.

이때, $isp$는 $S$ 안의 연산자 우선순위, $icp$는 입력될 때의 연산자 우선순위이다.

|연산자|$isp$|$icp$|
|---|---|---|
|`(`|`0`|`20`|
|`)`|`19`|`19`|
|`+`|`12`|`12`|
|`-`|`12`|`12`|
|`*`|`13`|`13`|
|`/`|`13`|`13`|
|`%`|`13`|`13`|
|`\0`|`0`|`0`|

`(`의 $isp$와 $icp$가 다른 점에 주목하자. `(`는 닫는 괄호가 입력될 때만 출력되어야 하므로 자연스럽게 이렇게 정의되어야 한다.

#### 후위 표기식의 계산

숫자를 저장하는 스택 $T$를 만들어 연산자가 주어지면 상위 2개를 `pop`한 후 연산하여 결과를 `push`하는 과정을 반복한다.


## 5. 큐

큐는 선입 선출 / FIFO 구조를 가지는 순서 리스트의 특별한 경우다.

큐의 용어들은 아래와 같다.

* `front`: 가장 앞의 원소
* `rear` / `back`: 가장 뒤의 원소
* `enQueue` / `push`: 큐에 원소를 추가
* `deQueue` / `pop`: 큐의 `front`를 제거하면서 반환

### 순차 자료구조(큐)

큐를 1차원 배열을 통해 구현하는 방법이다.

`front`는 첫 원소의 인덱스를, `rear`는 마지막 원소의 인덱스를 저장하는 정수로 아래와 같이 초기 / 공백 / 포화 상태를 구분한다.

* 초기 상태: `front = rear = -1`
* 공백 상태: `front = rear`
* 포화 상태: `rear = n - 1`

#### 장점

* 구현이 쉬움

#### 단점

* **표류 현상**이 일어난다.

### 표류 현상의 해결

첫 번째 방법은 `pop`이 일어날 때마다 원소들을 한 칸씩 미는 것이지만 이는 단점이 명확하고 서술할 가치가 없다.

두 번째 방법은 배열을 원형으로 사용하는 방법이다. 논리적으로 배열의 처음과 끝이 연결되었다고 가정한다.

이때, 공백 상태와 포화 상태를 구분하기 위해 `front`가 가리키는 한 칸은 비워 놓는다.

* 공백 상태: `front = rear`
* 포화 상태: `front = (rear + 1) mod M`

### [연결 자료구조(큐)](src/queue.c)

*구현 코드에서는 `rear` 대신 `back`을 사용함*

큐를 연결 리스트를 이용하여 구현하는 방법이다.

`front`는 연결 리스트의 head를 가리키는 포인터 변수, `rear`는 연결 리스트의 tail을 가리키는 포인터 변수로, 공백 상태를 확인할 수 있으며 포화 상태는 존재하지 않는다.

* 공백 상태: `front = rear = NULL`

### 덱

Double-ended queue

덱은 `push_front`, `push_back`, `pop_front`, `pop_back`이 모두 $O(1)$인 자료구조로, 비슷하게 원형 배열 또는 이중 연결 리스트로 구현된다.

## 6. 트리

### 이진 트리

정의: 공집합이거나 왼쪽 서브트리 및 오른쪽 서브트리가 각각 이진 트리인 노드의 유한 집합

종류는 아래와 같다.

* 포화 이진 트리: 높아기 $h$일 때 $2^{h+1} - 1$개의 노드가 있는 이진 트리
* 완전 이진 트리: 높이가 $h$, 노드 수가 $N \le 2^{h+1} - 1$일 때 그 노드의 위치가 포화 이진 트리에서의 $1$번부터 $N$번 노드까지의 위치가 완전히 일치하는 이진 트리
* 편향 이진 트리: 높이가 $h$, 노드 수가 $h+1$이며 자식의 뱡향이 모두 같은 이진 트리

순차 자료구조(배열) 또는 포인터로 구현되며, 배열로 구현할 경우 인덱스 $i$의 자식은 $2i$와 $2i+1$에, 부모는 $i/2$에 저장되어 있다.

### [이진 탐색 트리](src/binary_search_tree.c)

각 데이터마다 `key`가 있으며, 각 부모 노드마다 왼쪽 서브트리의 모든 노드의 `key`가 더 작거나 같고, 오른쪽 서브트리의 모든 노드의 `key`가 더 크거나 같은 이진 트리.

#### 연산
* 삽입
* 삭제
* 탐색: 높이가 $h$일 때 $O(h)$만에 원하는 `key`를 탐색할 수 있다.

### AVL 트리

*2021년 1학기 기말에 AVL 트리의 회전 연산을 구현하는 문제가 출제되었으며, 이 이외에는 구현은 출제된 적이 없다. 따라서 AVL 트리의 구현 문제는 어렵게 출제되지 않을 것으로 예상된다.*

#### BBST

트리의 높이를 최소화할 수 있도록 균형을 맞춰주는 조건을 추가하여 정의되는 이진 탐색 트리로, 대표적으로 AVL tree, Red-Black tree 등이 있다.

#### 특징

AVL 트리는 균형 인수 $BF = hL - hR$을 정의하여 self-balancing을 하며, AVL 트리의 연산이 끝난 후에는 모든 노드의 $|BF| \le 1$을 만족해야 한다.

삽입 / 삭제 후 이 조건을 맞추기 위해서 회전 연산을 한다. $BF = \pm 2$인 노드를 $P$라 했을 때 각각의 회전 연산의 조건은 아래와 같다.

* LL 회전: $BF(P) = 2, BF(C) \ge 0$, $C$는 왼쪽 자식
* RR 회전: $BF(P) = -2, BF(C) \le 0$, $C$는 오른쪽 자식
* LR 회전: $BF(P) = 2, BF(C) < 0$, $C$는 왼쪽 자식
* RR 회전: $BF(P) = -2, BF(C) > 0$, $C$는 오른쪽 자식

#### LL, RR 회전

LL 회전을 기준으로 $C$를 $P$ 자리로 옮기고, $P$를 $C$의 왼쪽 자식으로 놓는다. 이때 $C$의 왼쪽 자식은 $P$의 오른쪽 자식이 된다.

LL 회전은 right rotation을 함에 주의하자.

![LL](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbiiR2r%2FbtrJUY5baM4%2FyUDa0wduJaJ4pmL0glLMl1%2Fimg.png)
img from https://yoongrammer.tistory.com/72

#### LR, RL 회전

LR 회전을 기준으로 서술한다.

$C$의 오른쪽 자식을 $G$라 하자. 

* left rotation을 통해 $G$를 $C$의 자리로 옮기고, $C$는 $G$의 왼쪽 자식이 되도록 한다.
* right rotation을 통해 $G$를 $P$의 자리로 옮기고, $P$는 $G$의 오른쪽 자식이 되도록 한다.

![LR](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbqqYJK%2FbtrTfOfWWBd%2FKVynhLISaSx98MoUoNORY1%2Fimg.png)
img from https://yoongrammer.tistory.com/72

### [Heap](src/heap.c)

#### 필요성

우선순위 큐는 우선순위가 가장 높은 원소를 가장 먼저 삭제하는 자료구조이다. 이를 순차 자료구조로 구현할 경우 삽입 똔느 삭제가 비효율적이게 된다. 하지만 이를 heap으로 구현할 경우 $O(\log N)$ 시간에 삽입과 삭제를 할 수 있다.

#### Heap

서술의 기준을 max heap으로 통일한다.

정의: 완전 이진 트리이며 모든 노드가 모든 자손 노드의 `key`값보다 크거나 같다.

#### 연산

* `top`: 루트 노드의 `key`값을 반환한다.
* `insert`: Max heap을 유지하며 원소를 삽입한다.
* `delete`: 루트 노드를 제거하며 그 `key`값을 반환한다.

#### 구현

보통 완전 이진 트리의 배열 표현을 통해서 구현한다.

`insert` 연산의 경우, 배열의 끝에 원소를 추가한 후 그의 부모 노드와 값을 비교해 `swap`하는 것을 반복한다.

`delete` 연산의 경우, 루트 노드를 제거한 후 마지막 원소를 루트 노드로 올린 뒤 자식 노드 중 큰 값과 비교해 `swap`하는 것을 반복한다.

## 7. 정렬

모든 정렬은 오름차순 정렬 기준으로 서술한다.

### 정렬 방법의 분류

* 실행 방법에 따른 분류
    * 비교식 정렬: 비교할 키 값을 한 번에 두 개씩 비교하여 교환함으로써 하는 정렬
    * 분배식 정렬: 자료를 여러 개의 부분집합으로 분해하고, 각 부분집합별로 자료를 정렬함으로써 전체를 정렬
* 정렬 장소
    * 내부 정렬: 컴퓨터의 메모리 내부(주기억장치)에서 정렬
    * 외부 정렬: 보조기억장치에서 정렬

#### 내부 정렬

* 컴퓨터의 메모리 내부에서 정렬하는 방식
* 빠르지만 매우 큰 용량의 데이터는 정렬할 수 없음

내부 정렬의 분류

* 비교식 정렬
    * 교환 방식(Selection / Bubble / Quick)
    * 삽입 방식(Insertion)
    * 병합 방식(Merge)
    * 선택 방식(Heap)
* 분배식 정렬
    * 분배 방식(Radix)

#### 외부 정렬

* 느리지만 대용량의 데이터 정렬 가능
* 병합 방식: 파일을 부분 파일로 분리하여 내부 정렬 방식으로 정렬한 후 병합하는 방식(Merge)

### Selection / Bubble / Insertion Sort

* 선택 정렬: $i$번째에 들어갈 원소를 선택
* 버블 정렬: $A[i]>A[i+1]$일 때 교환
* 삽입 정렬: $i$번째 원소를 어디에 삽입할지 선택

|방식|최선|최악|평균|
|-|-|-|-|
|선택|$O(N^2)$|$O(N^2)$|$O(N^2)$|
|버블|$O(N^2)$|$O(N^2)$|$O(N^2)$|
|삽입|$O(N)$|$O(N^2)$|$O(N^2)$|

#### 삽입 정렬

* 데이터의 수가 적을 때 매우 빠름
* 또는 순서에 맞지 않은 레코드가 매우 적을 때 빠름
    * LOO(Left Out of Order): $R_i < \max_{1\le j < i} R_j$인 $R_i$

삽입 정렬의 변형

* 이진 삽입 정렬: binary search로 삽입할 곳을 찾음
* 연결 삽입 정렬: 리스트의 원소를 연결 리스트로 표현

### [Shell Sort](src/shellsort.c)

* 일정한 간격으로 떨어져 있는 자료들끼리 부분집합을 구성
* 각 부분집합마다 삽입 정렬을 수행
* 간격을 줄이면서 위 과정 반복

보통 부분집합의 기준이 되는 간격을 $N/2$에서 반씩 줄여 가며 수행한다.

* inplace sorting
* 일반적인 시간 복잡도 $O(N^{1.5})$

### [Quick Sort](src/quicksort.c)

* pivot 기준으로 왼쪽에는 pivot보다 작은 원소, 오른쪽에는 pivot보다 큰 원소를 배치
* quick sort로 왼쪽/오른쪽 배열 정렬
* 사소한 구현 실수로 많이 틀리는데다 쓰레기 알고리즘, ppt 구현도 틀림

#### 시간복잡도

* 최선: $O(N\log N)$
* 최악: $O(N^2)$
* 평균: $O(N\log N)$

#### 변형

* 랜덤 pivot
* 처음, 중간, 마지막의 중앙값 pivot
* 퀵 소트 + 삽입 정렬 + ㅁㄴㅇㄹ

### Merge Sort

자명

### [Heap Sort](src/heapsort.c)

* Heap을 만들어서 원소를 정렬함
* ppt에 그림과 함께 나와 있는 것은 직관적인 heap sort
* 실제 구현은 inplace heap sort로 주어진 배열을 바로 heap으로 만들어 사용
* ppt 의사 코드 틀림

#### 시간복잡도

* 최선, 최악, ,평균 모두 $O(N\log N)$

### [Radix Sort](src/radixsort.c)

* 정렬할 원소의 키값에 해당하는 버킷에 분류(이때 버킷은 큐)
* 버킷의 순서대로 원소를 꺼내며 정렬
* 1의 자리 수 - k의 자리 수 - ...로 반복

#### 시간복잡도

* 기수 $R$, 자릿수 $D$에 대해 $O(D(N+R))$

### Tim Sort

*구현 문제는 한 번도 나온 적 없음*

* Merge sort + Binary Insertion sort
* 실제 데이터는 이미 충분히 정렬되어 있을 것으로 가정하며, 이런 데이터에 대해 고성능을 보이는 알고리즘

실제 팀 소트의 동작 과정은 아래와 같다. 손으로 팀 소트를 돌리는 문제가 나올 수 있기 때문에 알아두는 것이 좋음.

* 데이터를 $2^x$개씩 잘라서 각각을 이진 삽입 정렬로 정렬한 run을 생성한다.
    * 이때, 처음에 증가하는 순서이면 증가하는 run을, 감소하는 순서이면 감소하는 run을 만든다.
    * 만들고 난 후 뒤의 원소가 같은 방향으로 배열되어 있으면 run을 확장시킨다.
* 감소하는 방향으로 만들어진 run을 뒤집는다.
* 아래 조건을 만족하도록 run을 스택에 push/pop하며 정렬한다.
    * 스택의 top에서부터 읽었을 때 run의 원소의 개수가 $A$, $B$, $C$라 하면
    * $C > A + B$
    * $B > A$
        * 장점
        * 스택에 들어 있는 run의 수를 적게 유지할 수 있다.
        * 크기가 비슷한 run끼리 merge할 수 있다.
    * 이 조건을 만족하지 않는 run이 오면 병합 과정에 따라 병합한 후 push
* 스택의 top부터 run끼리 merge를 수행한다.
    * 이때 merge 과정이 필요 없는 원소들은 무시한다.
    * merge 과정이 필요한 run의 원소 중 더 적은 개수를 복사한다.

#### 시간복잡도

* 최선: $O(N)$
* 평균, 최악: $O(N\log N)$

## 8. 그래프

나머지들은 매우 직관적이고 자명한데, 수업에서는 이상한 알고리즘을 하나 소개한다.

### [Prim's Algorithm](src/prim.c)

* 현재까지 찾은 MST의 정점들의 집합을 $T$라 했을 때, $T$에 연결된 간선 중 최소 가중치 간선을 연결한다.
* 두 개의 배열을 통해 구현 가능
    * $dist$: $dist[i]$는 $i\not\in T$일 때 $i$와 $T$의 어떤 정점이 연결된 간선들 중 최소의 가중치를 저장한다.
    * $selected$: $i\in T$인지 여부를 저장한다.
* 이를 통해 반복문 두 개로 구현할 수 있으며, $O(V^2)$의 시간복잡도를 가진다.

## 9. 탐색

### 해싱

* 키값에 수식을 적용시켜 키가 저장된 위치를 얻는 방법

가장 간단한 해시 함수인 $h(k) = k \pmod M$를 통해 설명한다.

* 해시 테이블: $M$개의 버킷으로 구성된 테이블로, 하나의 버킷에 $s$개의 슬롯이 있음
* 충돌: $k_1\ne k_2, h(k_1) = h(k_2)$일 때, 버킷에 슬롯이 비어 있으면 같이 저장(동거자 관계)
* 오버플로우: 충돌이 슬롯보다 더 많이 생겨서 할당할 슬롯이 없는 경우

#### 좋은 해시 함수의 조건

* 계산이 빨라야 함
* 충돌이 적어야 함
* 해시 테이블이 고르게 분포할 수 있어야 함

#### 해시 함수의 종류

* 제산(division) 함수
    * $h(k) = k \pmod M$
    * 보통 큰 소수를 사용해서 고르게 분포하도록 함
* 승산 함수
    * 곱하기 연산을 사용하여 해싱하는 경우
    * 어떤 실수 $\alpha$를 곱해 소수점 아래 부분만을 취한 후 테이블 크기 $M$을 곱해 정수 값을 주소로 사용
* 폴딩 함수
    * 키가 해시 테이블의 크기보다 더 큰 경우에 주로 사용
    * 키의 비트를 $k$개씩의 묶음으로 분할
        * $101\ 011\ 111 \rightarrow 101 / 011 / 111$
    * 이동 폴딩
        * 이들을 더하거나 / XOR해서 사용
        * $101+011+111$
    * 경계 폴딩
        * 이웃한 묶음을 뒤집어서 더해서 사용
        * $101+\mathbf{110}+111$
* 중간 제곱 함수
    * 제곱을 한 뒤 적당한 중간 비트들을 고르는 방법
    * 제곱한 값의 중간은 대개 키의 모든 값과 관련이 있음
* 숫자 분석 함수
    * 적절한 진수로 변환한 후 각 자릿수의 분포를 계산하여 편중된 자리를 제거하고 사용
    * 가장 고르게 분포된 자릿수부터 해시 테이블 주소의 크기만큼 차례대로 만든 수를 역순으로 바꿔 주소로 사용
    * 즉 가장 작은 자리에 가장 고른 데이터가 오게 됨
* 진법 변환 함수
    * 키가 10진수가 아닐 때 10진수로 변환한 후 해시 테이블 크기만큼의 하위 자리의 수를 선택
* 비트 추출 함수
    * $M=2^k$일 때 임의의 $k$개 비트를 추출해서 사용하는 방법
    * 충돌이 발생할 가능성이 높기 때문에 비트의 분포를 확인하는 것이 좋음

#### 충돌 해결책

* 충돌이 발생하고 빈 버킷이 남아 있지 않으면 오버플로우가 발생함

#### 해결책의 분류

* 개방 주소법: 충돌이 일어났을 때 해시 테이블의 다른 위치에 저장
    * 선형 조사법, 이차 조사법, 이중 해싱법, 임의 조사법 등
* 체이닝: 하나의 위치가 여러 항목을 저장할 수 있도록 구조 변경

#### 해결책

* 선형 조사법
    * 충돌이 $ht[k]$에서 발생했을 때, 처음으로 비어 있는 $ht[k+i]$에 저장
    * 군집화와 결합 문제 발생
        * 군집화: 한 번 충돌이 시작되면 그 위치에 항목들이 집중
        * 결합: 유사한 값을 가지는 데이터기리 밀집됨
* 이차 조사법
    * 선형 조사법과 유사
    * $ht[k]$에서 충돌 발생하면 처음으로 비어 있는 $ht[k+i^2]$에 저장
    * 약한 군집화 여전히 존재, bucket에 공간이 있어도 찾지 못할 수 있음
* 이중 해싱법
    * 재해싱이라고도 함
    * 오버플로우가 발생했을 때 다른 해시 함수 $h'(k)$를 통해 저장
    * $h(k)$가 오버플로우 - 처음으로 비어 있는 $h(k) + i\cdot h'(k)$를 사용
* 체이닝
    * 오버플로우 문제를 연결 리스트로 해결
    * 버킷 내에서는 연결 리스트를 순차 탐색